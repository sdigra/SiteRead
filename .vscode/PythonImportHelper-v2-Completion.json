[
    {
        "label": "drive",
        "importPath": "google.colab",
        "description": "google.colab",
        "isExtraImport": true,
        "detail": "google.colab",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "metrics",
        "importPath": "sklearn",
        "description": "sklearn",
        "isExtraImport": true,
        "detail": "sklearn",
        "documentation": {}
    },
    {
        "label": "accuracy_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "train_test_split",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "GaussianNB",
        "importPath": "sklearn.naive_bayes",
        "description": "sklearn.naive_bayes",
        "isExtraImport": true,
        "detail": "sklearn.naive_bayes",
        "documentation": {}
    },
    {
        "label": "parse_cropobject_list",
        "importPath": "muscima.io",
        "description": "muscima.io",
        "isExtraImport": true,
        "detail": "muscima.io",
        "documentation": {}
    },
    {
        "label": "itertools",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "itertools",
        "description": "itertools",
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "image_to_arr",
        "kind": 2,
        "importPath": "naive_bayes_music_notes",
        "description": "naive_bayes_music_notes",
        "peekOfCode": "def image_to_arr(filename):\n    image = Image.open(filename).convert('L')\n    plt.imshow(image)\n    plt.show()\n    width, height = image.size\n    pixel_values = list(image.getdata())\n    pixel_values = np.array(pixel_values).reshape((width, height))\n    pixel_values = ((pixel_values / 17)).astype(int).astype(float)\n    return pixel_values\ntarget_dict = { \"rest_whole\" : 0, \"rest_half\" : 1, \"rest_quarter\" : 2, \"rest_eighth\" : 3, \"note_whole\" : 4, \"note_half\" : 5, \"note_quarter\" : 6, \"note_eighth\" : 7, \"note_eighth_beam\" : 8}",
        "detail": "naive_bayes_music_notes",
        "documentation": {}
    },
    {
        "label": "target_dict",
        "kind": 5,
        "importPath": "naive_bayes_music_notes",
        "description": "naive_bayes_music_notes",
        "peekOfCode": "target_dict = { \"rest_whole\" : 0, \"rest_half\" : 1, \"rest_quarter\" : 2, \"rest_eighth\" : 3, \"note_whole\" : 4, \"note_half\" : 5, \"note_quarter\" : 6, \"note_eighth\" : 7, \"note_eighth_beam\" : 8}\nimages = []\ntarget = np.array([])\npath = \"/content/drive/MyDrive/222_project/target_images/\"\nfor filename in os.listdir(path):\n    if filename.endswith(\"jpg\"): \n        images.append(image_to_arr(path+filename))\n        target = np.append(target, target_dict[filename[:len(filename)-6]])\nimages = np.array(images)\n# # debugging",
        "detail": "naive_bayes_music_notes",
        "documentation": {}
    },
    {
        "label": "images",
        "kind": 5,
        "importPath": "naive_bayes_music_notes",
        "description": "naive_bayes_music_notes",
        "peekOfCode": "images = []\ntarget = np.array([])\npath = \"/content/drive/MyDrive/222_project/target_images/\"\nfor filename in os.listdir(path):\n    if filename.endswith(\"jpg\"): \n        images.append(image_to_arr(path+filename))\n        target = np.append(target, target_dict[filename[:len(filename)-6]])\nimages = np.array(images)\n# # debugging\n# print(images[2])",
        "detail": "naive_bayes_music_notes",
        "documentation": {}
    },
    {
        "label": "target",
        "kind": 5,
        "importPath": "naive_bayes_music_notes",
        "description": "naive_bayes_music_notes",
        "peekOfCode": "target = np.array([])\npath = \"/content/drive/MyDrive/222_project/target_images/\"\nfor filename in os.listdir(path):\n    if filename.endswith(\"jpg\"): \n        images.append(image_to_arr(path+filename))\n        target = np.append(target, target_dict[filename[:len(filename)-6]])\nimages = np.array(images)\n# # debugging\n# print(images[2])\n# print(digits.images[0])",
        "detail": "naive_bayes_music_notes",
        "documentation": {}
    },
    {
        "label": "path",
        "kind": 5,
        "importPath": "naive_bayes_music_notes",
        "description": "naive_bayes_music_notes",
        "peekOfCode": "path = \"/content/drive/MyDrive/222_project/target_images/\"\nfor filename in os.listdir(path):\n    if filename.endswith(\"jpg\"): \n        images.append(image_to_arr(path+filename))\n        target = np.append(target, target_dict[filename[:len(filename)-6]])\nimages = np.array(images)\n# # debugging\n# print(images[2])\n# print(digits.images[0])\n# image = Image.open(\"/content/drive/MyDrive/222_project/target_images/black_white.jpg\").convert('L')",
        "detail": "naive_bayes_music_notes",
        "documentation": {}
    },
    {
        "label": "images",
        "kind": 5,
        "importPath": "naive_bayes_music_notes",
        "description": "naive_bayes_music_notes",
        "peekOfCode": "images = np.array(images)\n# # debugging\n# print(images[2])\n# print(digits.images[0])\n# image = Image.open(\"/content/drive/MyDrive/222_project/target_images/black_white.jpg\").convert('L')\n# plt.imshow(image)\n# plt.show()\nn_samples = len(images)\ndata = images.reshape((n_samples, -1))\nX_train, X_test, y_train, y_test = train_test_split(",
        "detail": "naive_bayes_music_notes",
        "documentation": {}
    },
    {
        "label": "n_samples",
        "kind": 5,
        "importPath": "naive_bayes_music_notes",
        "description": "naive_bayes_music_notes",
        "peekOfCode": "n_samples = len(images)\ndata = images.reshape((n_samples, -1))\nX_train, X_test, y_train, y_test = train_test_split(\n    data, target, test_size=0.5, shuffle=False)\nGNB_classifier = GaussianNB()\nGNB_classifier.fit(X_train, y_train)\npredicted = GNB_classifier.predict(X_test)\n_, axes = plt.subplots(2, 4)\nimages_and_labels = list(zip(images, target))\nfor ax, (image, label) in zip(axes[0, :], images_and_labels[:4]):",
        "detail": "naive_bayes_music_notes",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "naive_bayes_music_notes",
        "description": "naive_bayes_music_notes",
        "peekOfCode": "data = images.reshape((n_samples, -1))\nX_train, X_test, y_train, y_test = train_test_split(\n    data, target, test_size=0.5, shuffle=False)\nGNB_classifier = GaussianNB()\nGNB_classifier.fit(X_train, y_train)\npredicted = GNB_classifier.predict(X_test)\n_, axes = plt.subplots(2, 4)\nimages_and_labels = list(zip(images, target))\nfor ax, (image, label) in zip(axes[0, :], images_and_labels[:4]):\n    ax.set_axis_off()",
        "detail": "naive_bayes_music_notes",
        "documentation": {}
    },
    {
        "label": "GNB_classifier",
        "kind": 5,
        "importPath": "naive_bayes_music_notes",
        "description": "naive_bayes_music_notes",
        "peekOfCode": "GNB_classifier = GaussianNB()\nGNB_classifier.fit(X_train, y_train)\npredicted = GNB_classifier.predict(X_test)\n_, axes = plt.subplots(2, 4)\nimages_and_labels = list(zip(images, target))\nfor ax, (image, label) in zip(axes[0, :], images_and_labels[:4]):\n    ax.set_axis_off()\n    ax.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n    ax.set_title('Training: %i' % label)\nimages_and_predictions = list(zip(images[n_samples // 2:], predicted))",
        "detail": "naive_bayes_music_notes",
        "documentation": {}
    },
    {
        "label": "predicted",
        "kind": 5,
        "importPath": "naive_bayes_music_notes",
        "description": "naive_bayes_music_notes",
        "peekOfCode": "predicted = GNB_classifier.predict(X_test)\n_, axes = plt.subplots(2, 4)\nimages_and_labels = list(zip(images, target))\nfor ax, (image, label) in zip(axes[0, :], images_and_labels[:4]):\n    ax.set_axis_off()\n    ax.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n    ax.set_title('Training: %i' % label)\nimages_and_predictions = list(zip(images[n_samples // 2:], predicted))\nfor ax, (image, prediction) in zip(axes[1, :], images_and_predictions[:4]):\n    ax.set_axis_off()",
        "detail": "naive_bayes_music_notes",
        "documentation": {}
    },
    {
        "label": "images_and_labels",
        "kind": 5,
        "importPath": "naive_bayes_music_notes",
        "description": "naive_bayes_music_notes",
        "peekOfCode": "images_and_labels = list(zip(images, target))\nfor ax, (image, label) in zip(axes[0, :], images_and_labels[:4]):\n    ax.set_axis_off()\n    ax.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n    ax.set_title('Training: %i' % label)\nimages_and_predictions = list(zip(images[n_samples // 2:], predicted))\nfor ax, (image, prediction) in zip(axes[1, :], images_and_predictions[:4]):\n    ax.set_axis_off()\n    ax.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n    ax.set_title('Prediction: %i' % prediction)",
        "detail": "naive_bayes_music_notes",
        "documentation": {}
    },
    {
        "label": "images_and_predictions",
        "kind": 5,
        "importPath": "naive_bayes_music_notes",
        "description": "naive_bayes_music_notes",
        "peekOfCode": "images_and_predictions = list(zip(images[n_samples // 2:], predicted))\nfor ax, (image, prediction) in zip(axes[1, :], images_and_predictions[:4]):\n    ax.set_axis_off()\n    ax.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n    ax.set_title('Prediction: %i' % prediction)\nprint(\"\\nClassification report for classifier %s:\\n%s\\n\" % (GNB_classifier, metrics.classification_report(y_test, predicted)))\ndisp = metrics.plot_confusion_matrix(GNB_classifier, X_test, y_test)\ndisp.figure_.suptitle(\"Confusion Matrix\")\nprint(\"\\nConfusion matrix:\\n%s\" % disp.confusion_matrix)\nprint(\"\\nAccuracy of the Algorithm: \", GNB_classifier.score(X_test, y_test))",
        "detail": "naive_bayes_music_notes",
        "documentation": {}
    },
    {
        "label": "disp",
        "kind": 5,
        "importPath": "naive_bayes_music_notes",
        "description": "naive_bayes_music_notes",
        "peekOfCode": "disp = metrics.plot_confusion_matrix(GNB_classifier, X_test, y_test)\ndisp.figure_.suptitle(\"Confusion Matrix\")\nprint(\"\\nConfusion matrix:\\n%s\" % disp.confusion_matrix)\nprint(\"\\nAccuracy of the Algorithm: \", GNB_classifier.score(X_test, y_test))\nplt.show()",
        "detail": "naive_bayes_music_notes",
        "documentation": {}
    },
    {
        "label": "extract_notes_from_doc",
        "kind": 2,
        "importPath": "read_training_images",
        "description": "read_training_images",
        "peekOfCode": "def extract_notes_from_doc(cropobjects):\n    \"\"\"Finds all ``(full-notehead, stem)`` pairs that form\n    quarter or half notes. Returns two lists of CropObject tuples:\n    one for quarter notes, one of half notes.\n    :returns: quarter_notes, half_notes\n    \"\"\"\n    _cropobj_dict = {c.objid: c for c in cropobjects}\n    notes = []\n    for c in cropobjects:\n        if (c.clsname == 'notehead-full') or (c.clsname == 'notehead-empty'):",
        "detail": "read_training_images",
        "documentation": {}
    },
    {
        "label": "get_image",
        "kind": 2,
        "importPath": "read_training_images",
        "description": "read_training_images",
        "peekOfCode": "def get_image(cropobjects, margin=1):\n    \"\"\"Paste the cropobjects' mask onto a shared canvas.\n    There will be a given margin of background on the edges.\"\"\"\n    # Get the bounding box into which all the objects fit\n    top = min([c.top for c in cropobjects])\n    left = min([c.left for c in cropobjects])\n    bottom = max([c.bottom for c in cropobjects])\n    right = max([c.right for c in cropobjects])\n    # Create the canvas onto which the masks will be pasted\n    height = bottom - top + 2 * margin",
        "detail": "read_training_images",
        "documentation": {}
    },
    {
        "label": "show_mask",
        "kind": 2,
        "importPath": "read_training_images",
        "description": "read_training_images",
        "peekOfCode": "def show_mask(mask):\n    plt.imshow(mask, cmap='gray_r', interpolation='nearest')\n    plt.show()\ndef show_masks(masks, row_length=5):\n    n_masks = len(masks)\n    n_rows = n_masks // row_length + 1\n    n_cols = min(n_masks, row_length)\n    fig = plt.figure()\n    for i, mask in enumerate(masks):\n        plt.subplot(n_rows, n_cols, i+1)",
        "detail": "read_training_images",
        "documentation": {}
    },
    {
        "label": "show_masks",
        "kind": 2,
        "importPath": "read_training_images",
        "description": "read_training_images",
        "peekOfCode": "def show_masks(masks, row_length=5):\n    n_masks = len(masks)\n    n_rows = n_masks // row_length + 1\n    n_cols = min(n_masks, row_length)\n    fig = plt.figure()\n    for i, mask in enumerate(masks):\n        plt.subplot(n_rows, n_cols, i+1)\n        plt.imshow(mask, cmap='gray_r', interpolation='nearest')\n    # Let's remove the axis labels, they clutter the image.\n    for ax in fig.axes:",
        "detail": "read_training_images",
        "documentation": {}
    },
    {
        "label": "CROPOBJECT_DIR",
        "kind": 5,
        "importPath": "read_training_images",
        "description": "read_training_images",
        "peekOfCode": "CROPOBJECT_DIR = os.path.join(os.environ['HOME'], './musicma_training_set/data/cropobjects_withstaff')\ncropobject_fnames = [os.path.join(CROPOBJECT_DIR, f) for f in os.listdir(CROPOBJECT_DIR)]\ndocs = [parse_cropobject_list(f) for f in cropobject_fnames]\n# Bear in mind that the outlinks are integers, only valid within the same document.\n# Therefore, we define a function per-document, not per-dataset.\ndef extract_notes_from_doc(cropobjects):\n    \"\"\"Finds all ``(full-notehead, stem)`` pairs that form\n    quarter or half notes. Returns two lists of CropObject tuples:\n    one for quarter notes, one of half notes.\n    :returns: quarter_notes, half_notes",
        "detail": "read_training_images",
        "documentation": {}
    },
    {
        "label": "cropobject_fnames",
        "kind": 5,
        "importPath": "read_training_images",
        "description": "read_training_images",
        "peekOfCode": "cropobject_fnames = [os.path.join(CROPOBJECT_DIR, f) for f in os.listdir(CROPOBJECT_DIR)]\ndocs = [parse_cropobject_list(f) for f in cropobject_fnames]\n# Bear in mind that the outlinks are integers, only valid within the same document.\n# Therefore, we define a function per-document, not per-dataset.\ndef extract_notes_from_doc(cropobjects):\n    \"\"\"Finds all ``(full-notehead, stem)`` pairs that form\n    quarter or half notes. Returns two lists of CropObject tuples:\n    one for quarter notes, one of half notes.\n    :returns: quarter_notes, half_notes\n    \"\"\"",
        "detail": "read_training_images",
        "documentation": {}
    },
    {
        "label": "docs",
        "kind": 5,
        "importPath": "read_training_images",
        "description": "read_training_images",
        "peekOfCode": "docs = [parse_cropobject_list(f) for f in cropobject_fnames]\n# Bear in mind that the outlinks are integers, only valid within the same document.\n# Therefore, we define a function per-document, not per-dataset.\ndef extract_notes_from_doc(cropobjects):\n    \"\"\"Finds all ``(full-notehead, stem)`` pairs that form\n    quarter or half notes. Returns two lists of CropObject tuples:\n    one for quarter notes, one of half notes.\n    :returns: quarter_notes, half_notes\n    \"\"\"\n    _cropobj_dict = {c.objid: c for c in cropobjects}",
        "detail": "read_training_images",
        "documentation": {}
    },
    {
        "label": "qns_and_hns",
        "kind": 5,
        "importPath": "read_training_images",
        "description": "read_training_images",
        "peekOfCode": "qns_and_hns = [extract_notes_from_doc(cropobjects) for cropobjects in docs]\nqns = list(itertools.chain(*[qn for qn, hn in qns_and_hns]))\nhns = list(itertools.chain(*[hn for qn, hn in qns_and_hns]))\ndef get_image(cropobjects, margin=1):\n    \"\"\"Paste the cropobjects' mask onto a shared canvas.\n    There will be a given margin of background on the edges.\"\"\"\n    # Get the bounding box into which all the objects fit\n    top = min([c.top for c in cropobjects])\n    left = min([c.left for c in cropobjects])\n    bottom = max([c.bottom for c in cropobjects])",
        "detail": "read_training_images",
        "documentation": {}
    },
    {
        "label": "qns",
        "kind": 5,
        "importPath": "read_training_images",
        "description": "read_training_images",
        "peekOfCode": "qns = list(itertools.chain(*[qn for qn, hn in qns_and_hns]))\nhns = list(itertools.chain(*[hn for qn, hn in qns_and_hns]))\ndef get_image(cropobjects, margin=1):\n    \"\"\"Paste the cropobjects' mask onto a shared canvas.\n    There will be a given margin of background on the edges.\"\"\"\n    # Get the bounding box into which all the objects fit\n    top = min([c.top for c in cropobjects])\n    left = min([c.left for c in cropobjects])\n    bottom = max([c.bottom for c in cropobjects])\n    right = max([c.right for c in cropobjects])",
        "detail": "read_training_images",
        "documentation": {}
    },
    {
        "label": "hns",
        "kind": 5,
        "importPath": "read_training_images",
        "description": "read_training_images",
        "peekOfCode": "hns = list(itertools.chain(*[hn for qn, hn in qns_and_hns]))\ndef get_image(cropobjects, margin=1):\n    \"\"\"Paste the cropobjects' mask onto a shared canvas.\n    There will be a given margin of background on the edges.\"\"\"\n    # Get the bounding box into which all the objects fit\n    top = min([c.top for c in cropobjects])\n    left = min([c.left for c in cropobjects])\n    bottom = max([c.bottom for c in cropobjects])\n    right = max([c.right for c in cropobjects])\n    # Create the canvas onto which the masks will be pasted",
        "detail": "read_training_images",
        "documentation": {}
    },
    {
        "label": "qn_images",
        "kind": 5,
        "importPath": "read_training_images",
        "description": "read_training_images",
        "peekOfCode": "qn_images = [get_image(qn) for qn in qns]\nhn_images = [get_image(hn) for hn in hns]\ndef show_mask(mask):\n    plt.imshow(mask, cmap='gray_r', interpolation='nearest')\n    plt.show()\ndef show_masks(masks, row_length=5):\n    n_masks = len(masks)\n    n_rows = n_masks // row_length + 1\n    n_cols = min(n_masks, row_length)\n    fig = plt.figure()",
        "detail": "read_training_images",
        "documentation": {}
    },
    {
        "label": "hn_images",
        "kind": 5,
        "importPath": "read_training_images",
        "description": "read_training_images",
        "peekOfCode": "hn_images = [get_image(hn) for hn in hns]\ndef show_mask(mask):\n    plt.imshow(mask, cmap='gray_r', interpolation='nearest')\n    plt.show()\ndef show_masks(masks, row_length=5):\n    n_masks = len(masks)\n    n_rows = n_masks // row_length + 1\n    n_cols = min(n_masks, row_length)\n    fig = plt.figure()\n    for i, mask in enumerate(masks):",
        "detail": "read_training_images",
        "documentation": {}
    }
]